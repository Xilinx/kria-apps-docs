<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
<!-- OneTrust Cookies Consent Notice start for xilinx.github.io -->

<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="03af8d57-0a04-47a6-8f10-322fa00d8fc7" ></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice end for xilinx.github.io -->
<!-- Google Tag Manager -->
<script type="text/plain" class="optanon-category-C0002">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-5RHQV7');</script>
<!-- End Google Tag Manager -->
  <title>Setting Up the Board and Application Deployment &mdash; Kria™ KV260 2022.1 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Customizing the AI Models Used in the Application" href="customize_ai_models.html" />
    <link rel="prev" title="Design Overview" href="introduction.html" /> 
</head>

<body class="wy-body-for-nav">

<!-- Google Tag Manager -->
<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-5RHQV7" height="0" width="0" style="display:none;visibility:hidden" class="optanon-category-C0002"></iframe></noscript>
<!-- End Google Tag Manager --> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="../../../index.html" class="icon icon-home"> Kria™ KV260
            <img src="../../../_static/xilinx-header-logo.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                2022.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">SOM</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/">Landing Page</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/Kria_doc_map/map.htm">Kria Adventure Map</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/creating_applications.html">Application Development</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/ubuntu_support.html">Ubuntu Support</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/bootfw.html">Boot Firmware</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/openamp.html">OpenAMP</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/dfx.html">Dynamic Function eXchange</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/ipmi_eeprom.html">IPMI EEPROM Design Guide</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/yocto.html">Yocto Support</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/xen.html">XEN Support</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/kd240-docs.html">Kria KD240</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/kv260-docs.html">Kria KV260</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/kr260-docs.html">Kria KR260</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/KRS/">Kria Robotics Stack</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KV260 Applications</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../smartcamera_landing.html">Smart Camera</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../smartcamera_landing.html#overview">Overview</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../smartcamera_landing.html#quick-start">Quick Start</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Setting Up the Board and Application Deployment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#booting-up-linux">Booting Up Linux</a></li>
<li class="toctree-l4"><a class="reference internal" href="#application-specific-hardware-setup">Application Specific Hardware Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="#downloading-and-loading-the-application-firmware">Downloading and Loading the Application Firmware</a></li>
<li class="toctree-l4"><a class="reference internal" href="#docker-based-application-preparation">Docker-Based Application Preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-the-application">Run the Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="#files-structure-of-the-application">Files Structure of the Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="#next-steps">Next Steps</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../smartcamera_landing.html#tutorials">Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../smartcamera_landing.html#architecture">Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../smartcamera_landing.html#repository">Repository</a></li>
<li class="toctree-l2"><a class="reference internal" href="../smartcamera_landing.html#other">Other</a></li>
<li class="toctree-l2"><a class="reference internal" href="../smartcamera_landing.html#related-tutorials">Related Tutorials</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../aibox-reid/aibox_landing.html">AI Box ReID</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../defect-detect/defectdetect_landing.html">Defect Detect</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlp-smartvision/nlp_smartvision_landing.html">NLP SmartVision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../aibox/aibox-dist_landing.html">AI Box Distributed ReID</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bist/bist_landing.html">Built-In Self Test (BIST)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Releases</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/kv260/2021.1/build/html/index.html">2021.1</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/kv260/2020.2/build/html/index.html">2020.2</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: black" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Kria™ KV260</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../smartcamera_landing.html">Smart Camera</a> &raquo;</li>
      <li>Setting Up the Board and Application Deployment</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <table class="sphinxhide">
 <tr>
   <td align="center"><img src="../../media/xilinx-logo.png" width="30%"/><h1> Kria&trade; KV260 Vision AI Starter Kit Smart Camera Tutorial</h1>
   </td>
 </tr>
 <tr>
 <td align="center"><h1>Setting Up the Board and Application Deployment</h1> </td>
 </tr>
</table><div class="section" id="setting-up-the-board-and-application-deployment">
<h1>Setting Up the Board and Application Deployment<a class="headerlink" href="#setting-up-the-board-and-application-deployment" title="Permalink to this heading">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">¶</a></h2>
<p>This document describes how to set up the board, and run the smartcam application.</p>
<p>This guide and its prebuilt are targeted for Ubuntu® 22.04 and AMD 2022.1 toolchain. The previous version of this application (on AMD 2021.1 toolchain) targeted to PetaLinux is still available <a class="reference external" href="https://xilinx.github.io/kria-apps-docs/2021.1/build/html/index.html">online</a>.</p>
</div>
<div class="section" id="booting-up-linux">
<h2>Booting Up Linux<a class="headerlink" href="#booting-up-linux" title="Permalink to this heading">¶</a></h2>
<p>Before continuing with the smartcam application specific instructions, if you have not yet done so, boot Linux with the instructions from the <a class="reference internal" href="../../kria_starterkit_linux_boot.html"><span class="doc">Kria Starter Kit Linux boot</span></a> page.</p>
<blockquote>
<div><p><strong>NOTE:</strong> It is recommended that you start the smartcam application using the command line through an universal asynchronous receiver-transmitter (UART), instead of GNOME Desktop.</p>
</div></blockquote>
</div>
<div class="section" id="application-specific-hardware-setup">
<h2>Application Specific Hardware Setup<a class="headerlink" href="#application-specific-hardware-setup" title="Permalink to this heading">¶</a></h2>
<p>Besides the hardware configurations required in the <a class="reference internal" href="../../kria_starterkit_linux_boot.html"><span class="doc">Kria Starter Kit Linux boot</span></a> for booting Linux, the smartcam application requires the following hardware setup:</p>
<p><img alt="GitHub Logo" src="../../../_images/som-board.png" /></p>
<ul>
<li><p>Monitor:</p>
<p>Before booting, connect a 1080P/4K monitor to the board via either the DP or HDMI port.</p>
<p>A 4K monitor is the preferred option to demonstrate at the maximum supported resolution.</p>
</li>
<li><p>IAS sensor:</p>
<p>Before powering on, install an AR1335 sensor module in J7.</p>
</li>
<li><p>You can also use a USB webcam as an input device.</p>
<p>The webcam is an optional video input device supported in the application.</p>
<p>The recommended webcam is the <a class="reference external" href="https://www.logitech.com/en-in/products/webcams/brio-4k-hdr-webcam.960-001105.html">Logitech BRIO</a>.</p>
</li>
<li><p>Audio Pmod setup as RTSP audio input:</p>
<p>Audio Pmod is an optional audio input and output device. In the current release (22.1 update3), audio is not supported; see <a class="reference internal" href="issue-sc.html"><span class="doc">Known Issues</span></a> for details.</p>
<p>In the smartcam application, only RTSP mode <a class="reference external" href="#rtsp-audio">uses the audio input function</a> to capture audio. Audio is then sent together with the images as a RTSP stream and can be received at the client side.</p>
<p>To set it up, first install the Pmod to J2, then connect a microphone or any other sound input device to the <a class="reference external" href="https://store.digilentinc.com/pmod-i2s2-stereo-audio-input-and-output/">line input port</a>. A headphone with a microphone will not work—the device needs to be a dedicated input.</p>
<p>The smartcam application does not yet support speakers.</p>
</li>
</ul>
<div class="section" id="software-preparation">
<h3>Software Preparation<a class="headerlink" href="#software-preparation" title="Permalink to this heading">¶</a></h3>
<p>You will use a PC with network access to the board as the RTSP client machine.</p>
<p>Make sure that the PC and the KV260 Vision AI Starter Kit are on the same subnet mask.</p>
<p>On the client machine, to receive and play the RTSP stream, it is recommended that you install FFplay which is part of FFmpeg package.</p>
<ul class="simple">
<li><p>For Linux, you can install FFmpeg with the package manager of your distribution.</p></li>
<li><p>For Windows, you can find install instructions on <a class="reference external" href="https://ffmpeg.org/download.html">https://ffmpeg.org/download.html</a>.</p></li>
</ul>
<p>Other than FFplay, VLC can also be used to play the RTSP stream, but sometimes it does not work on some client machines, while the FFplay works well.</p>
</div>
</div>
<div class="section" id="downloading-and-loading-the-application-firmware">
<h2>Downloading and Loading the Application Firmware<a class="headerlink" href="#downloading-and-loading-the-application-firmware" title="Permalink to this heading">¶</a></h2>
<ol>
<li><p>Get the latest kv260-smartcam firmware package.</p>
<ul>
<li><p>Search for the package feed for packages compatible with the KV260.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ubuntu@kria:~$ sudo apt search xlnx-firmware-kv260
Sorting... Done
Full Text Search... Done
xlnx-firmware-kv260-aibox-reid/jammy <span class="m">0</span>.1-0xlnx1 arm64
FPGA firmware <span class="k">for</span> Xilinx boards - kv260 aibox-reid application

xlnx-firmware-kv260-benchmark-b4096/jammy <span class="m">0</span>.1-0xlnx1 arm64
FPGA firmware <span class="k">for</span> Xilinx boards - kv260 benchmark-b4096 application

xlnx-firmware-kv260-defect-detect/jammy <span class="m">0</span>.1-0xlnx1 arm64
FPGA firmware <span class="k">for</span> Xilinx boards - kv260 defect-detect application

xlnx-firmware-kv260-nlp-smartvision/jammy,now <span class="m">0</span>.1-0xlnx1 arm64 
FPGA firmware <span class="k">for</span> Xilinx boards - kv260 nlp-smartvision application

xlnx-firmware-kv260-smartcam/jammy <span class="m">0</span>.1-0xlnx1 arm64 <span class="o">[</span>installed<span class="o">]</span>
FPGA firmware <span class="k">for</span> Xilinx boards - kv260 smartcam application
</pre></div>
</div>
</li>
<li><p>Install the firmware binaries.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo apt install xlnx-firmware-kv260-smartcam
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Dynamically load the application package.</p>
<p>The firmware consist of a bitstream and device tree overlay (dtbo) file. The firmware is loaded dynamically on user request once Linux is fully booted. The xmutil utility can be used for that purpose.</p>
<ul>
<li><p>Disable the desktop environment.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo xmutil      desktop_disable
</pre></div>
</div>
<blockquote>
<div><p><strong>NOTE:</strong> Executing <code class="docutils literal notranslate"><span class="pre">xmutil</span> <span class="pre">desktop_disable</span></code> will cause the monitor to go blank. Use any serial terminal to continue issuing the Linux commands via port J4, and do not rely completely on the desktop environment.</p>
</div></blockquote>
<p>After running the application, the desktop environment can be enabled again with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo xmutil      desktop_enable
</pre></div>
</div>
</li>
<li><p>After installing the firmware, execute xmutil listapps to verify that it is captured under the listapps function and to have dfx-mgrd rescan and register all accelerators in the firmware directory tree.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo xmutil listapps
</pre></div>
</div>
</li>
<li><p>Switch to a different platform for a different application.</p>
<p>When there is already another accelerator/firmware being activated, unload it first, then switch to the kv260-smartcam application.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo xmutil unloadapp
sudo xmutil loadapp kv260-smartcam
</pre></div>
</div>
</li>
</ul>
</li>
</ol>
</div>
<div class="section" id="docker-based-application-preparation">
<h2>Docker-Based Application Preparation<a class="headerlink" href="#docker-based-application-preparation" title="Permalink to this heading">¶</a></h2>
<ul>
<li><p>Pull the 2022.1 Docker image for smartcam using the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker pull xilinx/smartcam:2022.1
</pre></div>
</div>
<ul>
<li><p>The storage volume on the SD card can be limited with multiple Dockers. If there are space issues, you can use following command to remove the existing container:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker rmi --force &lt;other containers&gt;
</pre></div>
</div>
</li>
<li><p>You can find the images installed with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker images
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Launch the Docker using the follwowing command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run <span class="se">\</span>
--env<span class="o">=</span><span class="s2">&quot;DISPLAY&quot;</span> <span class="se">\</span>
-h <span class="s2">&quot;xlnx-docker&quot;</span> <span class="se">\</span>
--env<span class="o">=</span><span class="s2">&quot;XDG_SESSION_TYPE&quot;</span> <span class="se">\</span>
--net<span class="o">=</span>host <span class="se">\</span>
--privileged <span class="se">\</span>
--volume<span class="o">=</span><span class="s2">&quot;</span><span class="nv">$HOME</span><span class="s2">/.Xauthority:/root/.Xauthority:rw&quot;</span> <span class="se">\</span>
-v /tmp:/tmp <span class="se">\</span>
-v /dev:/dev <span class="se">\</span>
-v /sys:/sys <span class="se">\</span>
-v /etc/vart.conf:/etc/vart.conf <span class="se">\</span>
-v /lib/firmware/xilinx:/lib/firmware/xilinx <span class="se">\</span>
-v /run:/run <span class="se">\</span>
-it xilinx/smartcam:2022.1 bash
</pre></div>
</div>
<p>It will launch the smartcam image in a new container.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>root@xlnx-docker/#
</pre></div>
</div>
</li>
<li><p>Get the demo video files suitable for the application:</p>
<p>To demonstrate the function of the application in case you have no MIPI and USB camera in hand, the file video source is also supported.</p>
<p>You can download video files from the following links, which are in MP4 format:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pixabay.com/videos/alley-people-walk-street-ukraine-39837/">Facedet/RefineDet AI Task</a></p></li>
<li><p><a class="reference external" href="https://pixabay.com/videos/freeway-traffic-cars-rainy-truck-8358/">ADAS SSD AI Task</a></p></li>
</ul>
<p>Then, you need to transcode it to the H264 file which is one supported input format.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ffmpeg -i input-video.mp4 -c:v libx264 -pix_fmt nv12 -vf <span class="nv">scale</span><span class="o">=</span><span class="m">1920</span>:1080 -r <span class="m">30</span> output.nv12.h264
</pre></div>
</div>
<p>Finally, upload or copy these transcoded H264 files to the board (by using scp, ftp, or copy them onto the SD card and find them in <code class="docutils literal notranslate"><span class="pre">/boot/firmware/</span></code>), place it to somewhere under <code class="docutils literal notranslate"><span class="pre">/tmp</span></code>, which will mapped to /tmp in the Docker container too.</p>
</li>
</ul>
</div>
<div class="section" id="run-the-application">
<h2>Run the Application<a class="headerlink" href="#run-the-application" title="Permalink to this heading">¶</a></h2>
<p>There are two ways to interact with the application.</p>
<div class="section" id="jupyter-notebook">
<h3>Jupyter Notebook<a class="headerlink" href="#jupyter-notebook" title="Permalink to this heading">¶</a></h3>
<ul>
<li><p>You need to run the following command to install the package shipped notebooks, which reside in <code class="docutils literal notranslate"><span class="pre">/opt/xilinx/kv260-smartcam/share/notebooks</span></code>, to the folder <code class="docutils literal notranslate"><span class="pre">/root/notebooks/smartcam</span></code>:</p>
<p><code class="docutils literal notranslate"><span class="pre">$</span> <span class="pre">smartcam-install.py</span></code></p>
<p>This script also provides more options to install the current application notebook to a specified location.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    usage: smartcam-install [-h] [-d DIR] [-f]

    Script to copy smartcam Jupyter notebook to user directory

    optional arguments:
      -h, --help         show this help message and exit
      -d DIR, --dir DIR  Install the Jupyter notebook to the specified directory.
      -f, --force        Force to install the Jupyter notebook even if the destination directory exists.
</pre></div>
</div>
</li>
<li><p>To launch the Jupyter Notebook on the target, run the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>jupyter-lab --notebook-dir<span class="o">=</span>/root/notebooks/smartcam --allow-root --ip<span class="o">=</span>ip-address <span class="p">&amp;</span> 
// fill <span class="k">in</span> ip-address from ifconfig, eth0
</pre></div>
</div>
<p>Output example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>I <span class="m">2022</span>-09-05 <span class="m">10</span>:26:26.644 LabApp<span class="o">]</span> JupyterLab extension loaded from /usr/local/lib/python3.10/dist-packages/jupyterlab
<span class="o">[</span>I <span class="m">2022</span>-09-05 <span class="m">10</span>:26:26.644 LabApp<span class="o">]</span> JupyterLab application directory is /usr/local/share/jupyter/lab
<span class="o">[</span>I <span class="m">2022</span>-09-05 <span class="m">10</span>:26:26.664 ServerApp<span class="o">]</span> jupyterlab <span class="p">|</span> extension was successfully loaded.
<span class="o">[</span>I <span class="m">2022</span>-09-05 <span class="m">10</span>:26:26.683 ServerApp<span class="o">]</span> nbclassic <span class="p">|</span> extension was successfully loaded.
<span class="o">[</span>I <span class="m">2022</span>-09-05 <span class="m">10</span>:26:26.685 ServerApp<span class="o">]</span> Serving notebooks from <span class="nb">local</span> directory: /root/notebooks/smartcam
<span class="o">[</span>I <span class="m">2022</span>-09-05 <span class="m">10</span>:26:26.685 ServerApp<span class="o">]</span> Jupyter Server <span class="m">1</span>.18.1 is running at:
<span class="o">[</span>I <span class="m">2022</span>-09-05 <span class="m">10</span>:26:26.685 ServerApp<span class="o">]</span> http://192.168.1.233:8888/lab?token<span class="o">=</span>385858bbf1e5541dbba08d811bcac67d805b051ef37c6211
<span class="o">[</span>I <span class="m">2022</span>-09-05 <span class="m">10</span>:26:26.686 ServerApp<span class="o">]</span>  or http://127.0.0.1:8888/lab?token<span class="o">=</span>385858bbf1e5541dbba08d811bcac67d805b051ef37c6211
<span class="o">[</span>I <span class="m">2022</span>-09-05 <span class="m">10</span>:26:26.686 ServerApp<span class="o">]</span> Use Control-C to stop this server and shut down all kernels <span class="o">(</span>twice to skip confirmation<span class="o">)</span>.
<span class="o">[</span>W <span class="m">2022</span>-09-05 <span class="m">10</span>:26:26.702 ServerApp<span class="o">]</span> No web browser found: could not locate runnable browser.
<span class="o">[</span>C <span class="m">2022</span>-09-05 <span class="m">10</span>:26:26.703 ServerApp<span class="o">]</span>

    To access the server, open this file <span class="k">in</span> a browser:
        file:///root/.local/share/jupyter/runtime/jpserver-40-open.html
    Or copy and paste one of these URLs:
        http://192.168.1.233:8888/lab?token<span class="o">=</span>385858bbf1e5541dbba08d811bcac67d805b051ef37c6211
    or http://127.0.0.1:8888/lab?token<span class="o">=</span>385858bbf1e5541dbba08d811bcac67d805b051ef37c6211
</pre></div>
</div>
</li>
<li><p>You can access the server by opening the server URL from the previous steps with a Chrome browser.</p>
<p>In the notebook, the GStreamer pipeline string is constructed; you can get it by adding simple python code to print it out and played with gst-launch-1.0 command in the console, and there are some user options variables that can be changed and run with. For other parts of the pipeline, you can also change and play to see the effect easily.</p>
</li>
</ul>
</div>
<div class="section" id="command-line">
<h3>Command Line<a class="headerlink" href="#command-line" title="Permalink to this heading">¶</a></h3>
<p>These allow you to define different video input and output device targets using the smartcam application. Execute using the UART/debug interface.</p>
<div class="section" id="example-scripts">
<h4>Example Scripts<a class="headerlink" href="#example-scripts" title="Permalink to this heading">¶</a></h4>
<p>The following example scripts and options definitions are provided.</p>
<p>Refer to <a class="reference external" href="#script-loc">File Structure</a> to find the file locations.</p>
<details>
<summary><b>Click here to view the example script usage</b></summary><ul>
<li><p>MIPI RTSP server:</p>
<ol>
<li><p>Invoking <code class="docutils literal notranslate"><span class="pre">&quot;bash</span> <span class="pre">01.mipi-rtsp.sh&quot;</span></code> will start the RTSP server for the MIPI captured images.</p></li>
<li><p>The script accepts ${width} ${height} as the first and second parameter; the default is 1920 x 1080.</p></li>
<li><p>Running the script will display a message in the following form:</p>
<blockquote>
<div><p>stream ready at:</p>
<p>rtsp://boardip:port/test</p>
<p>Run “ffplay rtsp://boardip:port/test” on the client PC to receive the rtsp stream.</p>
</div></blockquote>
</li>
<li><p>Checking:</p>
<p>You should be able to see the images the camera is capturing on the FFplay window, and when there is a face captured by the camera, there should be blue box drawn around the face, and the box should follow the movement of the face.</p>
</li>
</ol>
</li>
<li><p>MIPI DP display:</p>
<ol>
<li><p>Make sure the monitor is connected as described <a class="reference external" href="#Setting-Up-the-Board">here</a>.</p></li>
<li><p>Invoking <code class="docutils literal notranslate"><span class="pre">&quot;bash</span> <span class="pre">02.mipi-dp.sh&quot;</span></code> will play the captured video with the detection results on the monitor.</p></li>
<li><p>The script accepts ${width} ${height} as the first and second parameter; the default is 1920 x 1080.</p></li>
<li><p>Checking:</p>
<p>You should be able to see the images the camera is capturing on the monitor connected to the board, and when there is a face captured by the camera, there should be blue box drawn around the face, and the box should follow the movement of the face.</p>
</li>
</ol>
</li>
<li><p>File to File</p>
<ol>
<li><p>Invoking <code class="docutils literal notranslate"><span class="pre">&quot;bash</span> <span class="pre">03.file-file.sh&quot;</span></code>.</p>
<p>Take the first argument passed to this script as the path to the H264 video file (you can use the demo video for face detection or similar videos), perform face detection, generate video with detection bbox, and save as <code class="docutils literal notranslate"><span class="pre">./out.h264</span></code>.</p>
</li>
<li><p>Checking:</p>
<p>Play the input video file and generated video file, <code class="docutils literal notranslate"><span class="pre">./out.h264</span></code>, with any media player you prefer, that is, VLC or FFPlay. You should be able to see in the output video file, there are blue boxes around the faces of people, and the boxes should follow the movement of the faces, while there are no such boxes with the input video file.</p>
</li>
</ol>
</li>
<li><p>File to DP</p>
<ol>
<li><p>Invoking <code class="docutils literal notranslate"><span class="pre">&quot;bash</span> <span class="pre">04.file-ssd-dp.sh&quot;</span></code>.</p>
<p>Take the first argument passed to this script as the path to the H264 video file (you can use the demo video for ADAS SSD or similar videos), perform vehicles detection and generate video with detection bbox, and display onto monitor</p>
</li>
<li><p>Checking:</p>
<p>You should be able to see a video of a highway driving with the detection of the vehicles in a bounding box.</p>
</li>
</ol>
</li>
</ul>
</details></div>
<div class="section" id="additional-configuration-options-for-the-smartcam-invocation">
<h4>Additional Configuration Options for the <code class="docutils literal notranslate"><span class="pre">smartcam</span></code> Invocation<a class="headerlink" href="#additional-configuration-options-for-the-smartcam-invocation" title="Permalink to this heading">¶</a></h4>
<p>The example scripts and Jupyter Notebook work as examples to show the capability of the smartcam application for specific configurations. More combinations could be made based on the options provided by the smartcam application. You can get detailed application options by invoking <code class="docutils literal notranslate"><span class="pre">smartcam</span> <span class="pre">--help</span></code>.</p>
<div class="section" id="usage">
<h5>Usage<a class="headerlink" href="#usage" title="Permalink to this heading">¶</a></h5>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span> smartcam [OPTION?] - Application for face detection on the SOM board of Xilinx.

 Help Options:

 -h, --help             Show help options

 --help-all             Show all help options

 --help-gst             Show GStreamer Options


 Application Options:

 -m, --mipi=                Use the MIPI camera as input source, auto detect, fail if no MIPI. available.

 -u, --usb=media_ID         USB camera video device id ( for example, 2 for /dev/video2)

 -f, --file=file            Path location of the h26x file as the input.

 -i, --infile-type=h264     Input file type: [h264 | h265]

 -W, --width=1920           Resolution w of the input.

 -H, --height=1080          Resolution h of the input.

 -r, --framerate=30         Framerate of the input.

 -t, --target=dp            [dp|rtsp|file]

 -o, --outmedia-type=h264   Output file type: [h264 | h265].

 -p, --port=5000            Port to listen on (default: 5000).

 -a, --aitask               Select the AI task to be run: [facedetect|ssd|refinedet].

 -n, --nodet                No AI inference.

 -A, --audio                RTSP with I2S audio input.

 -R, --report               Report fps

 -s, --screenfps            Display fps on the screen. Notic this will cause perfermance degradation.

 --ROI-off                  turn off ROI (Region-of-Interest)

--control-rate=low-latency  Encoder parameter control-rate
                            Supported value:
                            ((0): disable (1): variable (2): constant
                            (2130706434): capped-variable
                            (2130706433): low-latency)

--target-bitrate=3000       Encoder parameter target-bitrate

--gop-length=60             Encoder parameter gop-length

--profile                   Encoder parameter profile.
                            Default: h264: constrained-baseline; h264: main
                            Supported value:
                            (H264: constrained-baseline, baseline, main, high, high-10, high-4:2:2, high-10-intra, high-4:2:2-intra
                             H265: main, main-intra, main-10, main-10-intra, main-422-10, main-422-10-intra)

--level                     Encoder parameter level
                            Default: 4
                            Supported value:
                            (4, 4.1, 5, 5.1, 5.2)

--tier                      Encoder parameter tier
                            Default: main
                            Supported value:
                            (main, high)

--encodeEnhancedParam       String for fully customizing the encoder in the form &quot;param1=val1, param2=val2,...&quot;, where paramn is the name of the encoder parameter
                            For detailed info about the parameter name and value range, just run gst-inspect-1.0 omxh264enc / gst-inspect-1.0 omxh265enc based on the encoding type selected by option &quot;--outmedia-type&quot;, the parameter could be any of the listed parameters except &quot;control-rate, target-bitrate, gop-length&quot; which have dedicated options as above.
</pre></div>
</div>
</div>
<div class="section" id="examples-of-supported-combinations-sorted-by-input-are-outlined-below">
<h5>Examples of supported combinations sorted by input are outlined below<a class="headerlink" href="#examples-of-supported-combinations-sorted-by-input-are-outlined-below" title="Permalink to this heading">¶</a></h5>
<p>If using the command line to invoke the smartcam application, stop the process via CTRL + C prior to starting the next instance.</p>
<ul>
<li><p>MIPI Input (IAS sensor input):</p>
<ul>
<li><p>Output: RTSP</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>smartcam --mipi -W <span class="m">1920</span> -H <span class="m">1080</span> --target rtsp
</pre></div>
</div>
</li>
<li><p>Output: RTSP with audio <a name="rtsp-audio"> </a></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>smartcam --mipi -W <span class="m">1920</span> -H <span class="m">1080</span> --target rtsp --audio
</pre></div>
</div>
</li>
<li><p>Output: DP</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>smartcam --mipi -W <span class="m">1920</span> -H <span class="m">1080</span> --target dp
</pre></div>
</div>
</li>
<li><p>Output: file</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>smartcam --mipi -W <span class="m">1920</span> -H <span class="m">1080</span> --target file
</pre></div>
</div>
<blockquote>
<div><p><strong>NOTE:</strong> The output file is <code class="docutils literal notranslate"><span class="pre">./out.h264</span></code>.</p>
</div></blockquote>
</li>
</ul>
</li>
<li><p>Input file (file on file system):</p>
<blockquote>
<div><p><strong>NOTE:</strong> You must update the command to the specific file desired as the input source.</p>
</div></blockquote>
<ul>
<li><p>Output: RTSP</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>smartcam --file ./test.h264 -i h264 -W <span class="m">1920</span> -H <span class="m">1080</span> -r <span class="m">30</span> --target rtsp
</pre></div>
</div>
</li>
<li><p>Output: DP</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>smartcam --file ./test.h264 -i h264 -W <span class="m">1920</span> -H <span class="m">1080</span> -r <span class="m">30</span> --target dp
</pre></div>
</div>
</li>
<li><p>Output: file</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>smartcam --file ./test.h264 -i h264 -W <span class="m">1920</span> -H <span class="m">1080</span> -r <span class="m">30</span> --target file
</pre></div>
</div>
<blockquote>
<div><p><strong>NOTE:</strong> The output file is <code class="docutils literal notranslate"><span class="pre">./out.h264</span></code>.</p>
</div></blockquote>
</li>
</ul>
</li>
<li><p>Input USB (USB webcam):</p>
<blockquote>
<div><p><strong>NOTE:</strong> You must ensure the width/height/framerate defined are supported by your USB camera.</p>
</div></blockquote>
<ul>
<li><p>Output: RTSP</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>smartcam --usb <span class="m">1</span> -W <span class="m">1920</span> -H <span class="m">1080</span> -r <span class="m">30</span> --target rtsp
</pre></div>
</div>
</li>
<li><p>output: DP</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span> smartcam --usb <span class="m">1</span> -W <span class="m">1920</span> -H <span class="m">1080</span> -r <span class="m">30</span> --target dp
</pre></div>
</div>
</li>
<li><p>Output: file</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span> smartcam --usb <span class="m">1</span> -W <span class="m">1920</span> -H <span class="m">1080</span> -r <span class="m">30</span> --target file
</pre></div>
</div>
<blockquote>
<div><p><strong>NOTE:</strong> The output file is <code class="docutils literal notranslate"><span class="pre">./out.h264</span></code>.</p>
</div></blockquote>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="section" id="files-structure-of-the-application">
<h2>Files Structure of the Application<a class="headerlink" href="#files-structure-of-the-application" title="Permalink to this heading">¶</a></h2>
<p>The application is installed as follows.</p>
<ul class="simple">
<li><p>Binary File Directory: <code class="docutils literal notranslate"><span class="pre">/opt/xilinx/kv260-smartcam/bin</span></code></p></li>
</ul>
<table border="1" class="docutils">
<thead>
<tr>
<th>Filename</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>smartcam</td>
<td>main app</td>
</tr>
</tbody>
</table><ul class="simple">
<li><p>Script File Directory: <code class="docutils literal notranslate"><span class="pre">/opt/xilinx/kv260-smartcam/bin/</span></code> <a name="script-loc"></a></p></li>
</ul>
<table border="1" class="docutils">
<thead>
<tr>
<th>Filename</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>01.mipi-rtsp.sh</td>
<td>Call smartcam to run facedetction and send out rtsp stream.</td>
</tr>
<tr>
<td>02.mipi-dp.sh</td>
<td>Call smartcam to run facedetction and display on DP display.</td>
</tr>
<tr>
<td>03.file-file.sh</td>
<td>Call smartcam to run facedetction and display on input h264/5 file and generate output h264/5 with detection boxes.</td>
</tr>
<tr>
<td>04.file-ssd-dp.sh</td>
<td>Call smartcam to run ssd, process the input h264/5 file, and display the results with detection boxes DP display.</td>
</tr>
</tbody>
</table><ul>
<li><p>Configuration File Directory: <code class="docutils literal notranslate"><span class="pre">/opt/xilinx/kv260-smartcam/share/vvas/${AITASK}</span></code></p>
<p>AITASK = “facedetect” | “refinedet” | “ssd”</p>
</li>
</ul>
<table border="1" class="docutils">
<thead>
<tr>
<th>Filename</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>preprocess.json</td>
<td>Config of preprocess for AI inference</td>
</tr>
<tr>
<td>aiinference.json</td>
<td>Config of AI inference (facedetect|refinedet|ssd)</td>
</tr>
<tr>
<td>drawresult.json</td>
<td>Config of boundbox drawing</td>
</tr>
</tbody>
</table><ul class="simple">
<li><p>Model files: =&gt; <code class="docutils literal notranslate"><span class="pre">/opt/xilinx/kv260-smartcam/share/vitis_ai_library/models</span></code></p></li>
</ul>
<p>The model files integrated in the application use the B3136 DPU configuration.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Foldername</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>densebox_640_360</td>
<td>Model files for facedetcet</td>
</tr>
<tr>
<td>refinedet_pruned_0_96</td>
<td>Model files for refinedet</td>
</tr>
<tr>
<td>ssd_adas_pruned_0_95</td>
<td>Model files for ssd</td>
</tr>
</tbody>
</table><ul class="simple">
<li><p>Jupyter Notebook file: =&gt; <code class="docutils literal notranslate"><span class="pre">/opt/xilinx/kv260-smartcam/share/notebooks/</span></code></p></li>
</ul>
<table border="1" class="docutils">
<thead>
<tr>
<th>Filename</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>smartcam.ipynb</td>
<td>Jupyter Notebook file for MIPI/USB --&gt; DP/RTSP demo.</td>
</tr>
</tbody>
</table></div>
<div class="section" id="next-steps">
<h2>Next Steps<a class="headerlink" href="#next-steps" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>Go back to the <a class="reference internal" href="../smartcamera_landing.html"><span class="doc">KV260 SOM Smart Camera Design Start Page</span></a>.</p></li>
</ul>
<p class="sphinxhide" align="center"><sub>Copyright © 2021-2024 Advanced Micro Devices, Inc</sub></p><p class="sphinxhide" align="center"><sup><a href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a></sup></p></div>
</div>


           </div>
          </div>
          
				  
				  <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="introduction.html" class="btn btn-neutral float-left" title="Design Overview" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="customize_ai_models.html" class="btn btn-neutral float-right" title="Customizing the AI Models Used in the Application" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021-2024, Advanced Micro Devices, Inc.
      <span class="lastupdated">Last updated on March 21, 2024.
      </span></p>
  </div>



										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">

													                    <div class="row">
                        <div class="col-xs-24">
                          <p><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a> | <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a> | <a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a> | <a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a> | <a href="#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></p>
                        </div>
                    </div>
												</div>
											</div>
										</div>
										
</br>


  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>