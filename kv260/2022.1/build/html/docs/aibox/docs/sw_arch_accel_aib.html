<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
<!-- OneTrust Cookies Consent Notice start for xilinx.github.io -->

<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="03af8d57-0a04-47a6-8f10-322fa00d8fc7" ></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice end for xilinx.github.io -->
<!-- Google Tag Manager -->
<script type="text/plain" class="optanon-category-C0002">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-5RHQV7');</script>
<!-- End Google Tag Manager -->
  <title>Software Architecture of the Application &mdash; Kria™ KV260 2022.1 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Hardware Architecture of the Platform" href="hw_arch_platform_aib.html" />
    <link rel="prev" title="Software Architecture of the Platform" href="sw_arch_platform_aib.html" /> 
</head>

<body class="wy-body-for-nav">

<!-- Google Tag Manager -->
<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-5RHQV7" height="0" width="0" style="display:none;visibility:hidden" class="optanon-category-C0002"></iframe></noscript>
<!-- End Google Tag Manager --> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="../../../index.html" class="icon icon-home"> Kria™ KV260
            <img src="../../../_static/xilinx-header-logo.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                2022.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">SOM</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/">Landing Page</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/creating_applications.html">Application Development</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/ubuntu_support.html">Ubuntu Support</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/bootfw.html">Boot Firmware</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/openamp.html">OpenAMP</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/drm.html">Digital Rights Management</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/dfx.html">Dynamic Function eXchange</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/ipmi_eeprom.html">IPMI EEPROM Design Guide</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/kr260-docs.html">Kria KR260</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/KRS/">Kria Robotics Stack</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KV260 Applications</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../smartcamera/smartcamera_landing.html">Smart Camera</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../aibox-reid/aibox_landing.html">AI Box ReID</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../aibox-dist_landing.html">AI Box Distributed ReID</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../aibox-dist_landing.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aibox-dist_landing.html#quick-start">Quick Start</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aibox-dist_landing.html#tutorials">Tutorials</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../aibox-dist_landing.html#architecture">Architecture</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="sw_arch_platform_aib.html">Software Architecture - Platform</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Software Architecture - Accelerator</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#software-platform-and-dependencies">Software Platform and Dependencies</a></li>
<li class="toctree-l4"><a class="reference internal" href="#overview-of-the-distributed-application">Overview of The Distributed Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="#server-application-image-capturing-and-streaming">Server Application: Image Capturing and Streaming</a></li>
<li class="toctree-l4"><a class="reference internal" href="#client-application-monitor-center-tracking-and-rendering">Client Application: Monitor Center Tracking and Rendering</a></li>
<li class="toctree-l4"><a class="reference internal" href="#next-step">Next Step</a></li>
<li class="toctree-l4"><a class="reference internal" href="#license">License</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="hw_arch_platform_aib.html">Hardware Architecture - Platform</a></li>
<li class="toctree-l3"><a class="reference internal" href="hw_arch_accel_aib.html">Hardware Architecture - Accelerator</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../aibox-dist_landing.html#other">Other</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../defect-detect/defectdetect_landing.html">Defect Detect</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlp-smartvision/nlp_smartvision_landing.html">NLP SmartVision</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Releases</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/kv260/2021.1/build/html/index.html">2021.1</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/kria-apps-docs/kv260/2020.2/build/html/index.html">2020.2</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: black" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Kria™ KV260</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../aibox-dist_landing.html">AI Box Distributed ReID</a> &raquo;</li>
      <li>Software Architecture of the Application</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/docs/aibox/docs/sw_arch_accel_aib.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <table class="sphinxhide">
 <tr>
   <td align="center"><img src="../../media/xilinx-logo.png" width="30%"/><h1>Kria&trade; KV260 Vision AI Starter Kit AI Box Distributed Tutorial</h1>
   </td>
 </tr>
 <tr>
 <td align="center"><h1> Software Architecture of the Application</h1> </td>
 </tr>
</table><div class="section" id="software-architecture-of-the-application">
<h1>Software Architecture of the Application<a class="headerlink" href="#software-architecture-of-the-application" title="Permalink to this heading">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">¶</a></h2>
<p>This document describes the software architecture of the AI Box Distributed application.</p>
</div>
<div class="section" id="software-platform-and-dependencies">
<h2>Software Platform and Dependencies<a class="headerlink" href="#software-platform-and-dependencies" title="Permalink to this heading">¶</a></h2>
<p>We leverage the GStreamer multi-media orchestration platform for application software development. As described in following sections about GStreamer pipeline, all the processing units in the stream pipeline are presented to the user as easily pluggable and changeable plugins, enabling a “low touch” developer adaptation of the reference design pipeline within the context of an open-source and non-vendor specific implementation.</p>
<p><strong>Vitis AI 2.5.0</strong> is the core underlying component to access the AI inference capability provided by Xilinx DPU.</p>
<p>To access DPU and other PL hardware accelerator functions from GStreamer, Xilinx developed Vitis Video Analysis SDK (VVAS) to provide convenient and customizable GStreamer plugins for it.</p>
</div>
<div class="section" id="overview-of-the-distributed-application">
<h2>Overview of The Distributed Application<a class="headerlink" href="#overview-of-the-distributed-application" title="Permalink to this heading">¶</a></h2>
<p><img alt="Overall video data flow" src="../../../_images/aibox-dist-diagram.png" /></p>
<p>The AI Box Distributed application supports up to 4 distributed SOM with Camera to capture, inference and stream(<strong>1080p, H264/H265</strong>), and 1 dedicated monitoring center SOM with application which accepts up to 4 channels of RTSP streams from the remote IP Cameras.</p>
</div>
<div class="section" id="server-application-image-capturing-and-streaming">
<h2>Server Application: Image Capturing and Streaming<a class="headerlink" href="#server-application-image-capturing-and-streaming" title="Permalink to this heading">¶</a></h2>
<p>The distributed camera application supports capturing images (<strong>1080p, NV12</strong>) from MIPI/USB camera or decoding from on-disk video files, then performs pedestrian detection and pedestrian feature extraction on the stream using the AI inference accelerator (DPU). Next, orientation detection is performed on each detect pedestrian. Finally, the 3 kinds of info, bounding boxes, feature, and orientation are sent together with the encoded H264/H265 as RTSP stream.</p>
<p>As shown in following figures, decoded NV12 buffers are first pre-processed to prepare the buffer for ingestion by the pedestrian detection model in DPU. This includes color space conversion and resize operations.</p>
<p>The DPU then performs the inference with <strong>RefineDet</strong> on the incoming buffer, whose results are post-processed to get bounding box around and feature of each pedestrian. The bounding box information is then used to crop the region of interest for the detected person and DPU will run <strong>Orientation</strong> model on it to get orientation info of the pedestrian.</p>
<p><img alt="refinedet-inference-data-flow" src="../../../_images/aibox-dist-data_flow_refinedet.png" /></p>
<p>The figure above shows the GStreamer pipeline used in this application. There are 5 main components described below: Pedestrian Preprocess, Pedestrian Detection, Crop, ReID and Orientation, Meta Data Attaching.</p>
<ul>
<li><p>Pedestrian Preprocess</p>
<p>The pedestrian detection model requires downscaled BGR frames so the received decoded NV12 frames need to be pre-processed to do color space conversion and resizing. For best performance, these steps are performed using a dedicated pre-processing hardware accelerator IP, as described in the <a class="reference internal" href="hw_arch_accel_aib.html"><span class="doc">Hardware Accelerator Architecture</span></a></p>
<p>NV12 to BGR conversion and image resizing, are to meet the requirement of the DPU AI inference engine. These steps are done in one dedicate preprocessing IP, which is detailed in the <a class="reference external" href="../../smartcamera/docs/hw_arch_accel.md#pre-processing-ips-and-dpu">Accelerator IP Modules</a>, to achieve the optimal framerate and latency.</p>
<p>vvas_xmultisrc GStreamer plugin from VVAS with customized kernel /opt/xilinx/kv260-aibox-dist/lib/libvvas_pedpp.so are used to integrate the accelerator IP functionality into the pipeline.</p>
<p>Configuration file: /opt/xilinx/kv260-aibox-dist/share/vvas/ped_pp.json, contains the PL kernel and software kernel library info, which will do the colour conversion and resize.</p>
</li>
</ul>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="p">{</span><span class="w"></span>
<span class="w">      </span><span class="nt">&quot;kernel-name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;pp_pipeline_accel:{pp_pipeline_accel_1}&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">      </span><span class="nt">&quot;library-name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;libvvas_pedpp.so&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">      </span><span class="nt">&quot;config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;debug_level&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;mean_r&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;mean_g&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;mean_b&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;scale_r&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;scale_g&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;scale_b&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>
<span class="w">      </span><span class="p">}</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<ul>
<li><p>Pedestrian Detection</p>
<p>vvas_xfilter GStreamer plugin with kernel library /usr/lib/libvvas_dpuinfer.so works as middleware between the application which interfaces with user and underlying Vitis AI library. The Vits AI library then interfaces with DPU to feed the actual AI inference tasks.</p>
<p>Configuration file: /opt/xilinx/kv260-aibox-dist/share/vvas/refinedet.json, contains the actual model info we will run in this plugin.</p>
</li>
</ul>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="nt">&quot;config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;model-name&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;refinedet_pruned_0_96&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;model-class&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;REFINEDET&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;model-path&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;/opt/xilinx/kv260-aibox-dist/share/vitis_ai_library/models/&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;run_time_model&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;need_preprocess&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;performance_test&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="nt">&quot;debug_level&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<ul>
<li><p>Crop Plugin</p>
<p>Ivas_xfilter GStreamer plugin with kernel library /opt/xilinx/kv260-aibox-dist/lib/libvvas_crop.so will do the crop and resize on the input BGR image from previous pedestrian detection, based on the bbox info contained in the inference meta data, and attach the preprocessed images to the incoming inference meta data which will be passed down.</p>
<p>Configuration file: /opt/xilinx/kv260-aibox-dist/share/vvas/crop.json.</p>
</li>
<li><p>ReID and Orientation</p>
<p>vvas_xfilter GStreamer plugin with kernel library /opt/xilinx/kv260-aibox-dist/lib/libvvas_reid.so will run ReID on the incoming pedestrian images, get the ReID features, together with the coordinates of each person</p>
<p>Configuration file: /opt/xilinx/kv260-aibox-dist/share/vvas/reid.json.</p>
</li>
<li><p>Meta Data Attaching</p>
<p>This plugin will send the AI inference results including the bounding boxes, pedestrian features and pedestrian orientation through ZMQ to the monitoring client board. These info will be used to do cross camera tracking.</p>
</li>
</ul>
<div class="section" id="additional-gstreamer-component-used-in-server-app">
<h3>Additional GStreamer component used in Server App<a class="headerlink" href="#additional-gstreamer-component-used-in-server-app" title="Permalink to this heading">¶</a></h3>
<p>Gst-Rtsp-Server lib is utilized to build up the RTSP server video stream with AI detection results.</p>
</div>
</div>
<div class="section" id="client-application-monitor-center-tracking-and-rendering">
<h2>Client Application: Monitor Center Tracking and Rendering<a class="headerlink" href="#client-application-monitor-center-tracking-and-rendering" title="Permalink to this heading">¶</a></h2>
<p>At the monitor center, the application accepts the RTSP streams together with the AI inference meta data (bounding box, pedestrian feature and orientation) from remote camera, then decode the image stream, and perform the tracking algorithm on the meta data to obtain the cross camera ID for each pedestrian. Finally, bounding boxes and ID text are rendered over the original video frames and displayed on a <strong>4K</strong> monitor in a 2x2 grid.</p>
<p><img alt="client_monitor_data_flow" src="../../../_images/aibox-dist-monitor-data-flow.png" /></p>
<div class="section" id="xilinx-gstreamer-plugins">
<h3>Xilinx GStreamer Plugins<a class="headerlink" href="#xilinx-gstreamer-plugins" title="Permalink to this heading">¶</a></h3>
<ul>
<li><p>Meta Parser</p>
<p>MetaParser plugin receives the AI inference results and frame index info from server side and embeds it to the decoded buffers as meta data.</p>
</li>
<li><p>Cross Cameras Tracking</p>
<p>Accepts incominig buffers from the N (N&lt;=4) streams, and syncs them according to either timestamp or frame index, then feeds to the cross camera tracking algorithm to get the final ID info, and pass this info down to next stage.</p>
</li>
<li><p>AI Rendering</p>
<p>vvas_xfilter GStreamer plugin with kernel library /opt/xilinx/kv260-aibox-dist/lib/libvvas_drawreid.so will just draw the bounding box and ID for each detected person.</p>
<p>Configuration file: /opt/xilinx/kv260-aibox-dist/share/vvas/draw_reid.json.</p>
</li>
</ul>
</div>
<div class="section" id="additional-gstreamer-component-used-in-client-app">
<h3>Additional GStreamer component used in Client App<a class="headerlink" href="#additional-gstreamer-component-used-in-client-app" title="Permalink to this heading">¶</a></h3>
<p>The rtspsrc and omxh264dec are the standard GStreamer plugin which accept the RTSP stream and decode to NV12.</p>
</div>
</div>
<div class="section" id="next-step">
<h2>Next Step<a class="headerlink" href="#next-step" title="Permalink to this heading">¶</a></h2>
<p>You can choose any of the following next steps:</p>
<ul class="simple">
<li><p>Read <a class="reference internal" href="hw_arch_platform_aib.html"><span class="doc">Hardware Architecture of the Platform</span></a></p></li>
<li><p>Go back to the <a class="reference internal" href="../aibox-dist_landing.html"><span class="doc">KV260 AI Box design start page</span></a></p></li>
</ul>
</div>
<div class="section" id="license">
<h2>License<a class="headerlink" href="#license" title="Permalink to this heading">¶</a></h2>
<p>Licensed under the Apache License, Version 2.0 (the “License”); you may not use this file except in compliance with the License.</p>
<p>You may obtain a copy of the License at
<a class="reference external" href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></p>
<p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>
<p align="center">Copyright&copy; 2022 Xilinx</p></div>
</div>


           </div>
          </div>
          
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
				  
				  <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="sw_arch_platform_aib.html" class="btn btn-neutral float-left" title="Software Architecture of the Platform" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="hw_arch_platform_aib.html" class="btn btn-neutral float-right" title="Hardware Architecture of the Platform" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021-2023, Advanced Micro Devices, Inc.
      <span class="lastupdated">Last updated on February 3, 2023.
      </span></p>
  </div>



										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">

													                    <div class="row">
                        <div class="col-xs-24">
                          <p><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a> | <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a> | <a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a> | <a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a> | <a href="#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></p>
                        </div>
                    </div>
												</div>
											</div>
										</div>
										
</br>


  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>